import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Custom CSS for white background and light theme
st.markdown("""
<style>
    .main {
        background-color: white;
        color: black;
    }
    .stApp {
        background-color: white;
    }
    h1, h2, h3, h4, h5, h6, p, div, span {
        color: black !important;
    }
    .stMarkdown {
        color: black;
    }
</style>
""", unsafe_allow_html=True)

st.set_page_config(page_title="RoBERTa", page_icon="ü§ñ", layout="wide")
st.title(" Analyse de Sentiments avec RoBERTa")
st.caption("√âvaluation des avis touristiques de Marrakech √† l‚Äôaide d‚Äôun mod√®le Transformer pr√©-entra√Æn√©")

# Chargement des fichiers
df_roberta_full = pd.read_csv("../data/processed/results_roberta.csv")
df_roberta_test = pd.read_csv("../data/processed/results_roberta_test.csv")

# Section explication g√©n√©rale sur RoBERTa
st.markdown("## üîé Pr√©sentation du mod√®le RoBERTa")

st.markdown("""
RoBERTa (Robustly optimized BERT Pretraining Approach) est une version am√©lior√©e du c√©l√®bre mod√®le BERT de Google.  
Il s‚Äôagit d‚Äôun **mod√®le Transformer** pr√©-entra√Æn√© sur une tr√®s grande quantit√© de texte (milliards de phrases), puis fine-tun√© sur des t√¢ches d‚Äôanalyse de sentiments.
""")

# Expander pour le fonctionnement d√©taill√©
with st.expander("üîç Comment √ßa marche ?"):
    st.markdown("""
    - RoBERTa repose sur une **architecture Transformer** avec attention multi-t√™tes qui capture les relations complexes entre les mots dans une phrase.
    - Il a √©t√© entra√Æn√© avec plus de donn√©es et des optimisations (suppression du NSP, entra√Ænement plus long, batches plus grands) ‚Üí meilleures performances que BERT.
    - Pour l‚Äôanalyse de sentiments, on utilise g√©n√©ralement **"cardiffnlp/twitter-roberta-base-sentiment-latest"** ou un mod√®le similaire fine-tun√© sur des avis et tweets.
    - Le mod√®le comprend le **contexte bidirectionnel** (il lit la phrase dans les deux sens) ‚Üí tr√®s performant sur les phrases ambigu√´s, le sarcasme et les sentiments subtils.
    """)

# Expander pour les sorties du mod√®le
with st.expander("üìä Que produit RoBERTa ?"):
    st.markdown("""
    Pour chaque avis, RoBERTa retourne des **probabilit√©s (logits)** pour chaque classe :
    - Positive
    - Negative  
    - Neutral
    
    La classe pr√©dite est celle avec la probabilit√© la plus √©lev√©e.
    """)

# Expander pour forces et limites
with st.expander("üí° Forces et limites"):
    st.markdown("""
    **Forces :**
    - Tr√®s haute pr√©cision, surtout sur les sentiments nuanc√©s et ambigus
    - G√®re bien le langage informel, le sarcasme et les n√©gations complexes
    - Performances state-of-the-art sur la plupart des benchmarks de sentiment analysis
    
    **Limites :**
    - Plus lent et gourmand en ressources que VADER (n√©cessite GPU pour l‚Äôinf√©rence rapide)
    - Moins interpr√©table (bo√Æte noire)
    - Sensible √† la qualit√© du fine-tuning (le mod√®le utilis√© doit √™tre adapt√© au domaine)
    """)

st.markdown("Dans ce projet, RoBERTa repr√©sente l‚Äôapproche **deep learning moderne** et sert de r√©f√©rence performante face aux m√©thodes rule-based comme VADER et au mod√®le from scratch.")

st.markdown("## üìä Analyse globale des sentiments")

st.markdown("### R√©partition des pr√©dictions sur l‚Äôensemble du dataset")

col1, col2 = st.columns(2)

with col1:
    # Bar chart
    sent_count = df_roberta_full['roberta_sentiment'].value_counts().reset_index()
    sent_count.columns = ['Sentiment', 'Count']
    fig_bar = px.bar(sent_count, x='Sentiment', y='Count', color='Sentiment',
                     color_discrete_map={'Positive': 'green', 'Negative': 'red', 'Neutral': 'gray'},
                     title="Bar Chart",
                     width=500, height=400)
    st.plotly_chart(fig_bar, use_container_width=False)

with col2:
    # Pie chart
    fig_pie = px.pie(sent_count, names='Sentiment', values='Count', color='Sentiment',
                     color_discrete_map={'Positive': 'green', 'Negative': 'red', 'Neutral': 'gray'},
                     title="Pie Chart (Proportions)")
    st.plotly_chart(fig_pie, use_container_width=True)

st.markdown("## üß™ √âvaluation des performances sur le jeu de test")

st.markdown("""
Cette section √©value la performance de RoBERTa sur l'ensemble de test avec les m√©triques classiques.
""")

# Calcul des m√©triques
true_labels = df_roberta_test['sentiment_label']
pred_labels = df_roberta_test['roberta_sentiment']
accuracy = accuracy_score(true_labels, pred_labels)
report_dict = classification_report(true_labels, pred_labels, output_dict=True)

# Tableau styl√© du classification report
report_df = pd.DataFrame(report_dict).transpose().round(2)
report_df = report_df[['precision', 'recall', 'f1-score', 'support']]

def color_cells(val):
    if val >= 0.8:
        color = 'green'
    elif val >= 0.6:
        color = 'orange'
    else:
        color = 'red'
    return f'background-color: {color}; color: white'

styled_report = report_df.style.applymap(color_cells, subset=['precision', 'recall', 'f1-score'])

st.markdown("### Rapport de classification")

st.dataframe(styled_report)

# Matrice de confusion avec Plotly (couleurs vertes pour RoBERTa)
cm = confusion_matrix(true_labels, pred_labels, labels=['Positive', 'Negative', 'Neutral'])
fig_cm = ff.create_annotated_heatmap(
    z=cm,
    x=['Positive', 'Negative', 'Neutral'],
    y=['Positive', 'Negative', 'Neutral'],
    colorscale='Greens',  # Th√®me vert pour RoBERTa
    showscale=True
)
fig_cm.update_layout(title="Matrice de Confusion - RoBERTa (Test Set)", width=500, height=400)
st.plotly_chart(fig_cm, use_container_width=False)

# Interpr√©tation dynamique des r√©sultats
st.markdown("## üìù Interpr√©tation et analyse des r√©sultats")

st.markdown(f"""
RoBERTa atteint une accuracy globale de **{accuracy:.2%}** sur l'ensemble de test.

- **Performance par classe :**  
  - Positif : Pr√©cision de {report_dict['Positive']['precision']:.2f}, Rappel de {report_dict['Positive']['recall']:.2f}, F1-score de {report_dict['Positive']['f1-score']:.2f}. Tr√®s bonne d√©tection des avis positifs.  
  - N√©gatif : Pr√©cision de {report_dict['Negative']['precision']:.2f}, Rappel de {report_dict['Negative']['recall']:.2f}, F1-score de {report_dict['Negative']['f1-score']:.2f}. Bonne gestion du sarcasme et des n√©gations complexes.  
  - Neutre : Pr√©cision de {report_dict['Neutral']['precision']:.2f}, Rappel de {report_dict['Neutral']['recall']:.2f}, F1-score de {report_dict['Neutral']['f1-score']:.2f}. Meilleure compr√©hension des nuances que VADER.

Surprenant dans ce projet : RoBERTa (77.72%) est **d√©pass√© par le mod√®le from scratch**.  
Cela peut s‚Äôexpliquer par plusieurs facteurs :
- Le mod√®le RoBERTa utilis√© n‚Äô√©tait peut-√™tre pas parfaitement adapt√© au domaine touristique ou au style des avis (fine-tuning g√©n√©ral).
- Le dataset contient des avis en anglais avec un vocabulaire sp√©cifique √† Marrakech que le mod√®le from scratch, entra√Æn√© directement dessus, capture mieux via TF-IDF.
- RoBERTa reste sup√©rieur sur les cas ambigus et contextuels, mais le pr√©-traitement + r√©gression logistique s‚Äôav√®re ici plus efficace globalement.
""")