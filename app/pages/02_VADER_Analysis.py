import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# Custom CSS for white background and light theme
st.markdown("""
<style>
    .main {
        background-color: white;
        color: black;
    }
    .stApp {
        background-color: white;
    }
    h1, h2, h3, h4, h5, h6, p, div, span {
        color: black !important;
    }
    .stMarkdown {
        color: black;
    }
</style>
""", unsafe_allow_html=True)

st.set_page_config(page_title="VADER", page_icon="üíö", layout="wide")
st.title(" Analyse de Sentiments avec VADER")
st.caption("√âvaluation des avis touristiques de Marrakech √† l‚Äôaide d‚Äôun mod√®le lexicon-based")


# Chargement des fichiers
df_vader_full = pd.read_csv("../data/processed/results_vader.csv")
df_vader_test = pd.read_csv("../data/processed/results_vader_test.csv")

# Section explication g√©n√©rale sur VADER
st.markdown("## üîé Pr√©sentation du mod√®le VADER")


st.markdown("""
VADER (Valence Aware Dictionary and sEntiment Reasoner) est un outil d'analyse de sentiments simple mais puissant, sp√©cialement con√ßu pour les textes courts et expressifs comme les avis en ligne.
""")

# Expander pour le fonctionnement d√©taill√©
with st.expander("üîç Comment √ßa marche ?"):
    st.markdown("""
    VADER utilise un **lexique de plus de 7 500 mots** √©valu√©s par des humains sur une √©chelle de -4 √† +4.  
    Il applique aussi des **r√®gles grammaticales** pour comprendre l'intensit√© et la polarit√© des phrases.
    
    **Quelques subtilit√©s prises en compte :**
    - ‚ùå **N√©gation** : "pas bon" devient n√©gatif
    - üìà **Intensificateurs** : "tr√®s bon" augmente le score positif
    - ‚ùó **Ponctuation et majuscules** : "BON !!!" ‚Üí plus positif
    - üòÑ **Emojis, argot et acronymes** : ":)", "lol", "üíò"
    - ‚öñÔ∏è **Conjonctions contrastives** : "bon, mais mauvais" est analys√© correctement
    """)

# Expander pour les scores et r√©sultats
with st.expander("üìä Que produit VADER ?"):
    st.markdown("""
    Pour chaque texte, VADER calcule :  
    - **Score compos√©** entre -1 et +1
    - Proportions de **positif, n√©gatif et neutre**
    
    Cela permet de voir rapidement si un avis est globalement positif, n√©gatif ou neutre, m√™me avec des phrases informelles ou pleines d'√©motion.
    """)

# Expander pour forces et limites
with st.expander("üí° Forces et limites"):
    st.markdown("""
    **Forces :**
    - Excellent pour les textes courts et expressifs
    - Prend en compte emojis, ponctuation, argot  
    - Simple et rapide √† utiliser
    
    **Limites :**
    - Moins pr√©cis sur les phrases longues et complexes
    - Les sentiments ambigus ou subtils peuvent √™tre mal class√©s
    - Peut √™tre compl√©t√© par des mod√®les avanc√©s comme **RoBERTa** pour de meilleurs r√©sultats
    """)

st.markdown("VADER est donc id√©al pour une premi√®re analyse rapide des avis touristiques sur Marrakech, tout en pouvant √™tre combin√© avec des mod√®les plus sophistiqu√©s pour les cas plus subtils.")


st.markdown("## üìä Analyse globale des sentiments")


st.markdown("### R√©partition des pr√©dictions sur l‚Äôensemble du dataset")

# Use Plotly for bar chart with colors and smaller size
col1, col2 = st.columns(2)

with col1:
    # Bar chart
    sent_count = df_vader_full['vader_sentiment'].value_counts().reset_index()
    sent_count.columns = ['Sentiment', 'Count']
    fig_bar = px.bar(sent_count, x='Sentiment', y='Count', color='Sentiment',
                     color_discrete_map={'Positive': 'green', 'Negative': 'red', 'Neutral': 'gray'},
                     title="Bar Chart",
                     width=500, height=400)
    st.plotly_chart(fig_bar, use_container_width=False)

with col2:
    # Ajout : Pie chart
    fig_pie = px.pie(sent_count, names='Sentiment', values='Count', color='Sentiment',
                     color_discrete_map={'Positive': 'green', 'Negative': 'red', 'Neutral': 'gray'},
                     title="Pie Chart (Proportions)")
    st.plotly_chart(fig_pie, use_container_width=True)

st.markdown("## üß™ √âvaluation des performances sur le jeu de test")

st.markdown("""
Cette section √©value la performance de VADER sur l'ensemble de test. Nous utilisons des m√©triques comme la pr√©cision, le rappel, le F1-score et la matrice de confusion pour mesurer l'exactitude des pr√©dictions par rapport aux labels vrais.
""")

# Calcul des m√©triques
true_labels = df_vader_test['sentiment_label']
pred_labels = df_vader_test['vader_sentiment']
accuracy = accuracy_score(true_labels, pred_labels)
report_dict = classification_report(true_labels, pred_labels, output_dict=True)

# Convert classification report to DataFrame for table display
report_df = pd.DataFrame(report_dict).transpose().round(2)
report_df = report_df[['precision', 'recall', 'f1-score', 'support']]

# Style the table with colors
def color_cells(val):
    if val >= 0.7:
        color = 'green'
    elif val >= 0.5:
        color = 'orange'
    else:
        color = 'red'
    return f'background-color: {color}; color: white'

styled_report = report_df.style.applymap(color_cells, subset=['precision', 'recall', 'f1-score'])

st.markdown("### Rapport de classification")

st.dataframe(styled_report)

# Matrice de confusion avec Plotly heatmap pour couleurs et taille contr√¥l√©e
cm = confusion_matrix(true_labels, pred_labels, labels=['Positive', 'Negative', 'Neutral'])
fig_cm = ff.create_annotated_heatmap(
    z=cm,
    x=['Positive', 'Negative', 'Neutral'],
    y=['Positive', 'Negative', 'Neutral'],
    colorscale='Blues',
    showscale=True
)
fig_cm.update_layout(title="Matrice de Confusion - VADER (Test Set)", width=500, height=400)  # Smaller size
st.plotly_chart(fig_cm, use_container_width=False)

# Interpr√©tation dynamique des r√©sultats
st.markdown("## üìù Interpr√©tation et analyse des r√©sultats")

st.markdown(f"""
VADER atteint une accuracy globale de **{accuracy:.2%}** sur l'ensemble de test.

- **Performance par classe :**  
  - Positif : Pr√©cision de {report_dict['Positive']['precision']:.2f}, Rappel de {report_dict['Positive']['recall']:.2f}, F1-score de {report_dict['Positive']['f1-score']:.2f}. VADER identifie correctement les avis tr√®s expressifs et positifs.  
  - N√©gatif : Pr√©cision de {report_dict['Negative']['precision']:.2f}, Rappel de {report_dict['Negative']['recall']:.2f}, F1-score de {report_dict['Negative']['f1-score']:.2f}. Bonne sensibilit√© aux n√©gations et intensificateurs.  
  - Neutre : Pr√©cision de {report_dict['Neutral']['precision']:.2f}, Rappel de {report_dict['Neutral']['recall']:.2f}, F1-score de {report_dict['Neutral']['f1-score']:.2f}. Les avis neutres ou mod√©r√©s sont souvent mal class√©s, car VADER est optimis√© pour les polarit√©s fortes.

Dans ce projet, VADER obtient la **plus faible performance** parmi les trois approches (59.43%).  
Bien qu‚Äôil soit excellent pour les textes courts et tr√®s expressifs (emojis, ponctuation, majuscules), il peine sur les avis touristiques plus nuanc√©s ou longs typiques de Marrakech.  
Cela montre les limites d‚Äôune approche purement lexicon-based face √† des mod√®les entra√Æn√©s sur le dataset cible.
""")